---
title: "Part 2: NASA Crater Detection"
excerpt: "Mid-project update: crater detection on the Moon using YOLOv10 and Ellipse R-CNN"
date: 2025-03-28
layout: single
author_profile: true
read_time: true
share: true
related: true
classes: wide
categories:
  - deep-learning 
tags:
  - computer vision
  - object detection
  - deep learning
---

_This is Part 2 of a two-part series on crater detection using deep learning. [Missed Part 1? Catch up here â†’](https://anekha.github.io/deep-learning/2025/03/28/NASA.html)_

## ğŸš€ Overview

In Part 1, we built a **YOLOv10 + Ellipse R-CNN** pipeline to detect and localize lunar craters.

This post focuses on:
- ğŸŒ€ Rim-fitting using Ellipse R-CNN  
- ğŸ“Š Evaluation metrics and precision challenges  
- âš™ï¸ System integration and resource constraints  
- ğŸ” Final takeaways and next steps

---

ğŸ“º **Watch a 1-minute summary of the project:**

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; border-radius: 8px; margin-bottom: 1.5rem;">
  <iframe 
    src="https://www.youtube.com/embed/5sAfHHuAaLE?si=Jqw0OIvaw-Hfthlq" 
    title="NASA Crater Detection Summary"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border-radius: 8px;">
  </iframe>
</div>

---


## ğŸ§  From Boxes to Rims: LunarLens Pipeline

Our two-stage detection system â€” **LunarLens** â€” works like this:

1. **YOLOv10** detects crater bounding boxes quickly.  
2. **Ellipse R-CNN** then fits an ellipse to the rim of each crater.

This hybrid system balances speed with shape accuracy, ideal for autonomous space navigation.

![LunarLens Pipeline](/assets/projects/NASA/lunarlens_pipeline.png){: .center-image }

---

## ğŸŒ€ Postprocessing with Ellipse R-CNN

Bounding boxes from YOLOv10 are cropped and passed to Ellipse R-CNN, which predicts:

- (x, y) center  
- Major & minor axes  
- Orientation  

This gives us a mathematically accurate rim outline.

```text
Crater 1: (100.3, 40.8), (101.5, 39.6), ...
Crater 2: (463.2, 80.9), (462.3, 81.4), ...
```

## ğŸ“Š Evaluation & Metrics

We assessed detection quality at **IoU thresholds of 50% and 70%**, using AP, precision, and recall.

| Metric    | IoU = 50 | IoU = 70 |
|-----------|----------|----------|
| AP        | 0.111    | 0.003    |
| Recall    | 0.145    | 0.010    |
| Precision | 0.337    | 0.042    |

ğŸ§  **Key takeaway**: Precision drops sharply at high IoU â€” highlighting how tight rim localization is the hard part, not detection.

## ğŸ§ª System Performance Under Constraints

We were tasked with running this system on **CPU-only hardware** with Raspberry Piâ€“level specs.

| Constraint   | Result           |
|--------------|------------------|
| Image Size   | 5 MP             |
| Runtime      | ~20 sec / image  |
| RAM          | < 4 GB           |
| Hardware     | No GPU           |

---

## ğŸ” Final Thoughts & Next Steps

- âœ… **YOLOv10** was great for rapid detection, but rim precision required postprocessing.  
- âœ… **Ellipse R-CNN** helped convert detections into usable geometric inputs.  
- âš ï¸ Evaluation at high IoU exposed the need for better shape-fit training.

**Next steps:**
- Fine-tune Ellipse R-CNN on lunar tile crops  
- Apply weighted evaluation based on crater size  
- Improve YOLO thresholding and ensemble strategies  

---

## ğŸ¤ Acknowledgments

Built by: **Anekha Sokhal, Tian Le, Henry Tran, Juan Hevia, Madeleine Harrell, Jeremy Xu**
Mentored by: **Kyle Smith (NASA), Arko Barman, Ananya Muguli**

<div style="margin: 25px 0; display: flex; gap: 16px; flex-wrap: wrap; justify-content: center;">
  <img src="/assets/projects/NASA/nasa_team1.jpeg" alt="Team at NASA Johnson Space Center" style="width: 48%; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
  <img src="/assets/projects/NASA/nasa_team3.jpeg" alt="Team group photo at NASA" style="width: 48%; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
</div>

<div style="margin-top: 16px; text-align: center;">
  <img src="/assets/projects/NASA/nasa_2.jpeg" alt="Anekha in spacecraft cockpit at NASA" style="max-width: 50%; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.08);">
</div>

<p style="margin-top: 10px; font-style: italic; font-size: 0.9em; text-align: center; color: #555;">
  The team at NASA Johnson Space Center, Houston
</p>

---

ğŸ’¬ _Have questions, or want to explore vision systems for autonomous spacecraft?_  
**Feel free to reach out â€” Iâ€™d love to chat!**